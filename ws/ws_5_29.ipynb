{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append('../')\n",
    "import pickle\n",
    "from DJSCCv2 import *\n",
    "import torch\n",
    "from functions import Imageset\n",
    "from compressai.ops import compute_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "from pytorch_msssim import ms_ssim\n",
    "from tmp_functions import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- ZF\n",
      "interference_power:  tensor(2.5198e-16)\n",
      "interference_power:  tensor(9.5007e-16)\n",
      "sinr(linear):  [tensor(6377624.), tensor(2448929.5000)]\n",
      "sinr(dB):  tensor([6.8047, 6.3890])\n"
     ]
    }
   ],
   "source": [
    "Nt = 2\n",
    "U = 2\n",
    "torch.manual_seed(10)\n",
    "H = torch.Tensor([[1,0.1],[0.3,1]])\n",
    "P = [0.6846,0.2837]\n",
    "# p_noise = [0.3**2,0.15**2]\n",
    "p_noise = torch.Tensor([1,1])*1e-7\n",
    "mode = \"ZF\"\n",
    "W_dict = {\n",
    "    \"ZF\":F.normalize(H@torch.inverse(H.T@H),dim=0),\n",
    "    \"OPT\":torch.Tensor([[0.9976,-0.2448],[-0.0693,0.9696]]),\n",
    "    \"Random\":F.normalize(torch.randn(Nt,U),dim=0),\n",
    "    \"MRC\":F.normalize(H,dim=0)\n",
    "}\n",
    "sinr_downlink(W_dict,mode,P,H,p_noise)\n",
    "mu_miso = CHN_MU_MISO(W_dict[mode],H,P,p_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature map:  12\n"
     ]
    }
   ],
   "source": [
    "dev = 'cuda:7'\n",
    "with open('../savedmodels/model_snrdb_10_bwr_0.120_2024_01_23_02_38_04.pth.tar','rb') as f:\n",
    "    model0=pickle.load(f)\n",
    "model = Autoencoder(6.8,0.120,(3,256,256))\n",
    "model.load_state_dict(model0.state_dict())\n",
    "model = model.to(dev)\n",
    "dset = Imageset('../../compress_lip/Jianhao_datasets/CLIC/',transforms.Resize((256,256)),1,1,5)\n",
    "dloaders = []\n",
    "for u in range(U):\n",
    "    dloaders.append(dataloader.DataLoader(dset,1,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mse  ]: [N=5.00E+00] [EX:  3.826E-03] [VarX:  4.835E-06]\n",
      "[psnr ]: [N=5.00E+00] [EX:  2.489E+01] [VarX:  6.526E+00]\n",
      "[ssim ]: [N=5.00E+00] [EX:  9.785E-01] [VarX:  1.462E-04]\n",
      "[mse  ]: [N=5.00E+00] [EX:  3.826E-03] [VarX:  4.835E-06]\n",
      "[psnr ]: [N=5.00E+00] [EX:  2.489E+01] [VarX:  6.526E+00]\n",
      "[ssim ]: [N=5.00E+00] [EX:  9.785E-01] [VarX:  1.464E-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(10)\n",
    "\n",
    "perf_stats = [{\"mse\":RUN_STAT(\"mse\"),\"psnr\":RUN_STAT(\"psnr\"),\"ssim\":RUN_STAT(\"ssim\")}\n",
    "                 for _ in range(U)]\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(zip(*dloaders),total=len(dloaders[0])):\n",
    "        # x is the list of all users' images\n",
    "        # next: process the loaded images for the encoder\n",
    "        x = [xu.to(dev) for xu in x]\n",
    "        outenc = [model.encoder(xu) for xu in x]\n",
    "        # print(\"outenc: \", outenc[0].shape)\n",
    "        outchn = mu_miso(outenc)\n",
    "        # print(\"outchn: \", outchn.shape)\n",
    "        xhat = [model.decoder(outchn_) for outchn_ in outchn]\n",
    "        # print(\"outdec: \", xhat[0].shape)\n",
    "        # plt.figure()\n",
    "        # for u in range(len(x)):\n",
    "        #     plt.subplot(int(f\"2{U}{u+1}\"))\n",
    "        #     plt.imshow((x[u].squeeze().to('cpu')).permute(1,2,0))\n",
    "        #     plt.subplot(int(f\"2{U}{U+u+1}\"))\n",
    "        #     plt.imshow((xhat[u].squeeze().to('cpu')).permute(1,2,0))\n",
    "        #     # mse = torch.mean((x[u])**2)\n",
    "        #     # print(\"mse: \",u,mse)\n",
    "        for xu,xhatu,perf_stat in zip(x,xhat,perf_stats):\n",
    "            mse = torch.mean((xu-xhatu)**2)\n",
    "            # print(\"mse: \",u,mse)\n",
    "            mse = torch.mean((xu-xhatu)**2)\n",
    "            psnr = 10*np.log10(1/mse.item())\n",
    "            ssim = ms_ssim(xu,xhatu,data_range=1.)\n",
    "            perf_stat[\"mse\"](mse)\n",
    "            perf_stat[\"psnr\"](psnr)\n",
    "            perf_stat[\"ssim\"](ssim)\n",
    "for u in range(U):\n",
    "    for k,v in perf_stats[u].items():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5209, device='cuda:7'), torch.Size([1, 12, 64, 64]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(outenc[0]**2)/outenc[0][0].numel(),outenc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[my]: [N=1.00E+00] [EX:  1.000E+00] [VarX:  0.000E+00]\n"
     ]
    }
   ],
   "source": [
    "class RUN_STAT:\n",
    "    def __init__(self,name=\"\"):\n",
    "        self.name = name\n",
    "        self.num = 0\n",
    "        self.EX = 0\n",
    "        self.EX2 = 0\n",
    "    def __call__(self,x):\n",
    "        self.EX = (self.EX*self.num+x)/(self.num+1)\n",
    "        self.EX2= (self.EX2*self.num+x**2)/(self.num+1)\n",
    "        self.num += 1\n",
    "    def __str__(self):\n",
    "        var = self.EX2-(self.EX)**2\n",
    "        if self.name:\n",
    "            return f\"[{self.name}]: [N={self.num:5.2E}] [EX: {self.EX:10.3E}] [VarX: {var:10.3E}]\"\n",
    "        else:\n",
    "            return f\"[N={self.num:5.2E}] [EX: {self.EX:10.3E}] [VarX: {var:10.3E}]\"\n",
    "a = RUN_STAT(\"my\")\n",
    "a(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mse]: [N=5.00E+00] [EX:  5.012E-03] [VarX:  8.009E-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mse_stat = RUN_STAT(\"mse\")\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(dloaders[0]):\n",
    "        # x is the list of all users' images\n",
    "        # next: process the loaded images for the encoder\n",
    "        x = x.to(dev)\n",
    "        xhat = model(x)\n",
    "        mse = torch.mean((x-xhat)**2)\n",
    "        mse_stat(mse)\n",
    "print(mse_stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaiyuan_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
